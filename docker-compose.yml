services:
  # # # # # # # # # # # # # # # #
  ##### Day 2 - EDA / KAFKA #####
  # # # # # # # # # # # # # # # #
  # Zookeeper est là pour faire une mémoire partagée
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
  # Définition de mon broker KAFKA
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_BROKER_ID: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 2
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_CREATE_TOPICS: "velib_topic:1:2"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

    # Deuxième broker Kafka
  kafka2:
    image: wurstmeister/kafka
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka2:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_BROKER_ID: 2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8081:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092,kafka2:9093
      - KAFKA_CLUSTERS_0_ZOOKEEPER=kafka:2181
    depends_on:
      - kafka
      - kafka2

  producer:
    build: ./producer
    volumes:
      - ./producer:/app
    depends_on:
      - kafka
    environment:
      KAFKA_BROKER: kafka:9092
    command: python -u producer.py

  consumer:
    build: ./consumer
    volumes:
      - ./consumer:/app
    depends_on:
      - kafka
    environment:
      KAFKA_BROKER: kafka:9092
    command: python -u consumer.py

  # # # # # # # # # # # # #
  ##### Day 3 - HADOOP ####
  # # # # # # # # # # # # #
  namenode: # Controle le stockage dans les datanode
    image: apache/hadoop:3.4.1 #CentOS7
    hostname: namenode
    volumes:
      - ./namenode/Makefile:/opt/hadoop/Makefile # fichier qui contient les scripts d'initialisation du container
      - ./spark-scripts:/opt/zeppelin/notebook/spark-scripts
    ports:
      - 9870:9870 # HDFS webUI
      - 8080:8080 # Zeppelin webUI
    env_file:
      - ./config.env
    environment:
      # Définition du répertoire de stockage des métadonnées du NameNode
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    command: bash -c "\
      if ! rpm -q make > /dev/null 2>&1; then \
        echo 'Make not found. Installing...'; \
        sudo sed -i -e '/^mirrorlist/d;/^#baseurl=/{s,^#,,;s,/mirror,/vault,;}' /etc/yum.repos.d/CentOS*.repo && \
        sudo yum -y update && \
        sudo yum clean all && \
        sudo yum install -y make; \
      else \
        echo 'Make is already installed.'; \
      fi && \
      sudo make install-spark; \
      sudo make install-python3; \
      make install-zeppelin; \
      make start-namenode"
      
  datanode_1: # Stocke des datablocks
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - ./config.env
  datanode_2: # Stocke des datablocks
    image: apache/hadoop:3.4.1
    command: ["hdfs", "datanode"]
    env_file:
      - ./config.env

  resourcemanager: # gestion des ressources
    image: apache/hadoop:3.4.1
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"] # Commande de démarrage du resource manager YARN
    ports:
      - 8088:8088 # YARN webUI
    env_file:
      - ./config.env
  nodemanager: #  Gestion des noeuds
    image: apache/hadoop:3.4.1
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config.env
